{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 90FA-B9DB\n",
      "\n",
      " Directory of c:\\Users\\NB\\Documents\\Object Count CCTV\n",
      "\n",
      "02/29/2024  02:23 PM    <DIR>          .\n",
      "02/27/2024  04:09 PM    <DIR>          ..\n",
      "02/29/2024  11:14 AM                35 .env\n",
      "02/29/2024  11:14 AM               239 config.py\n",
      "02/28/2024  08:54 PM         3,407,916 output.mp4\n",
      "12/29/2023  03:20 PM            38,195 plot.png\n",
      "02/29/2024  02:37 PM            98,261 sandbox.ipynb\n",
      "02/29/2024  02:14 PM             2,441 sandbox.py\n",
      "02/29/2024  11:27 AM    <DIR>          storage\n",
      "02/29/2024  11:28 AM               863 Token.py\n",
      "02/28/2024  08:16 PM             5,570 Yolo.py\n",
      "02/28/2024  01:27 PM    <DIR>          YOLOv4\n",
      "02/29/2024  02:23 PM         6,534,387 yolov8n.pt\n",
      "02/29/2024  11:28 AM    <DIR>          __pycache__\n",
      "               9 File(s)     10,087,907 bytes\n",
      "               5 Dir(s)  140,165,128,192 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\nb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffpyplayer in c:\\users\\nb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ffpyplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\n",
      "ERROR: No matching distribution found for opencv\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\nb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\nb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Wait for 25ms and check if the user pressed 'q' to exit the loop\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ffpyplayer.player import MediaPlayer\n",
    "import cv2\n",
    "\n",
    "rtsp_url = 'rtsp://molecool:molec00l@10.212.45.176/h264'\n",
    "player = MediaPlayer(rtsp_url)\n",
    "\n",
    "while True:\n",
    "    frame, val = player.get_frame()\n",
    "    if not val != 'eof' and frame is not None:\n",
    "        # Display the frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Wait for 25ms and check if the user pressed 'q' to exit the loop\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "rtsp_url = 'rtsp://molecool:molec00l@10.212.45.176/h264'\n",
    "print('checkpoint')\n",
    "previewname = \"CCTV\"\n",
    "cv2.namedWindow(previewname)\n",
    "cam = cv2.VideoCapture(rtsp_url)\n",
    "if cam.isOpened():\n",
    "    rval, frame = cam.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(previewname, frame)\n",
    "    rval, frame = cam.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27:  # Press ESC to exit/close each window.\n",
    "        break\n",
    "cv2.destroyWindow(previewname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd C:\\Users\\NB\\Documents\\Object Count CCTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(frame)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Check for the ESC key to exit\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:  \u001b[38;5;66;03m# ESC key\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "STREAM_URL = \"https://cctv.molecool.id/Selong-001/video.m3u8?token=120e283a548e5754f093a6b5fe3dbaeda8fb5053-f1eff10322f29700440a9ada9c05921b-1709128873-1709125273\"\n",
    "\n",
    "# Open a VideoCapture object\n",
    "cam = cv2.VideoCapture(STREAM_URL)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not cam.isOpened():\n",
    "    print(\"Error: Failed to open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Get the dimensions of the video frames\n",
    "width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 25.0, (width, height))\n",
    "\n",
    "# Create a window to display the preview\n",
    "cv2.namedWindow(\"CCTV\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera feed\n",
    "    rval, frame = cam.read()\n",
    "    if not rval:\n",
    "        break\n",
    "\n",
    "    # Display the frame in the preview window\n",
    "    cv2.imshow(\"CCTV\", frame)\n",
    "\n",
    "    # Write the frame to the output video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Check for the ESC key to exit\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27:  # ESC key\n",
    "        break\n",
    "\n",
    "# Release the VideoWriter object and camera resources\n",
    "out.release()\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "STREAM_URL = \"https://cctv.molecool.id/Selong-001/video.m3u8?token=120e283a548e5754f093a6b5fe3dbaeda8fb5053-f1eff10322f29700440a9ada9c05921b-1709128873-1709125273\"\n",
    "\n",
    "print('checkpoint')\n",
    "cam = cv2.VideoCapture(STREAM_URL)\n",
    "if cam.isOpened():\n",
    "    rval, frame = cam.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    height, width, _ = frame.shape\n",
    "    resized_frame = cv2.resize(frame, (width // 2, height // 2))\n",
    "    cv2_imshow(resized_frame)\n",
    "    rval, frame = cam.read()\n",
    "    sleep(0.3)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTSP connection failed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# RTSP URL of the video stream\n",
    "rtsp_url = 'rtsp://molecool:molec00l@10.212.45.176/h264'\n",
    "cap = cv2.VideoCapture(rtsp_url)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if cap.isOpened():\n",
    "    print(\"RTSP connection successful.\")\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"RTSP connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = 'plot.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image from BGR to RGB (OpenCV reads images in BGR format)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'CAP_PROP_RTSP_USERNAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Set authentication parameters\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_RTSP_USERNAME\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmolecool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_RTSP_PASSWORD, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmolec00l\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Open the RTSP stream\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'CAP_PROP_RTSP_USERNAME'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# RTSP URL of the video stream\n",
    "rtsp_url = 'rtsp://10.212.45.176/h264'\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture()\n",
    "\n",
    "# Set authentication parameters\n",
    "cap.set(cv2.CAP_PROP_RTSP_USERNAME, 'molecool')\n",
    "cap.set(cv2.CAP_PROP_RTSP_PASSWORD, 'molec00l')\n",
    "\n",
    "# Open the RTSP stream\n",
    "cap.open(rtsp_url)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Couldn't open the video stream.\")\n",
    "    exit()\n",
    "\n",
    "# Read and display frames from the video stream\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Check if the user pressed 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "None\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Loading yolov8_best_visdrone.onnx for ONNX Runtime inference...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx'] not found, attempting AutoUpdate...\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "Frame Queue Length: 0\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache \"onnx\" ' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import config\n",
    "from Token import FlusonicToken\n",
    "import queue\n",
    "import threading\n",
    "from Yolo import Yolov4\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import object_counter\n",
    "from ultralytics.solutions import speed_estimation\n",
    "import cv2\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "FPS=30\n",
    "MAX_QUEUE_SIZE = FPS*2\n",
    "FRAME_DISPLAY_INTERVAL = 1 / FPS\n",
    "QUEUE_SIZE_MINIMUM_THRESHOLD = (MAX_QUEUE_SIZE/2)\n",
    "\n",
    "yolo_obj = Yolov4()\n",
    "yolov8_obj = YOLO(\"yolov8_best_visdrone.onnx\")\n",
    "\n",
    "token_generator = FlusonicToken('Gelora-009', 10).get_tokenized_url()\n",
    "stream_url = token_generator\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)\n",
    "stream = cv2.VideoCapture(stream_url)\n",
    "\n",
    "# region_points = [(20, 400), (1080, 404), (1080, 360), (20, 360)]\n",
    "# counter = object_counter.ObjectCounter()\n",
    "# counter.set_args(view_img=False,\n",
    "#                  reg_pts=region_points,\n",
    "#                  classes_names=yolov8_obj.names,\n",
    "#                  draw_tracks=True)\n",
    "\n",
    "\n",
    "line_pts = [(0, 360), (1280, 360)]\n",
    "speed_obj = speed_estimation.SpeedEstimator()\n",
    "names = yolov8_obj.names\n",
    "speed_obj.set_args(reg_pts=line_pts,\n",
    "                   names=names,\n",
    "                   view_img=False)\n",
    "\n",
    "print(yolov8_obj.names)\n",
    "\n",
    "\n",
    "\n",
    "def get_polyline_dist(polyline_points, frame, box_centroid_x, box_centroid_y, box_w, box_h):\n",
    "    text = \"test\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = .8\n",
    "    font_thickness = 2\n",
    "\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "\n",
    "    box_half_w = box_w // 2\n",
    "    box_half_h = box_h // 2\n",
    "\n",
    "    box_top_left_x=int(box_centroid_x-box_half_w)\n",
    "    box_top_left_y=int(box_centroid_y-box_half_h)\n",
    "    top_left_box = (box_top_left_x, box_top_left_y)\n",
    "\n",
    "    box_top_right_x=int(box_centroid_x+box_half_w)\n",
    "    box_top_right_y=int(box_centroid_y-box_half_h)\n",
    "    top_right_box = (box_top_right_x, box_top_right_y)\n",
    "\n",
    "    box_bottom_right_x=int(box_centroid_x+box_half_w)\n",
    "    box_bottom_right_y=int(box_centroid_y+box_half_h)\n",
    "    bottom_right_box = (box_bottom_right_x, box_bottom_right_y)\n",
    "\n",
    "    box_bottom_left_x=int(box_centroid_x-box_half_w)\n",
    "    box_bottom_left_y=int(box_centroid_y+box_half_h)\n",
    "    bottom_left_box = (box_bottom_left_x, box_bottom_left_y)\n",
    "\n",
    "    cv2.circle(frame, (top_left_box), radius=2, color=(255, 0, 0), thickness=2)\n",
    "    cv2.circle(frame, (top_right_box), radius=2, color=(255, 0, 0), thickness=2)\n",
    "    cv2.circle(frame, (bottom_left_box), radius=2, color=(255, 0, 0), thickness=2)\n",
    "    cv2.circle(frame, (bottom_right_box), radius=2, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "\n",
    "    bottom_right = (int(box_top_left_x + text_size[0]), int(box_top_left_y + 10))\n",
    "    cv2.rectangle(\n",
    "        frame,\n",
    "        top_left_box,\n",
    "        (box_top_left_x + text_w, box_top_left_y + text_h),\n",
    "        (255, 255, 255),\n",
    "        thickness=cv2.FILLED\n",
    "    )\n",
    "    # cv2.rectangle(frame, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    # cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "    \n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        text,\n",
    "        (box_top_left_x, int(box_top_left_y + text_h)),\n",
    "        font,\n",
    "        font_scale,\n",
    "        (0, 0, 0),\n",
    "        font_thickness,\n",
    "    )\n",
    "\n",
    "def read_frames(yolo_obj):\n",
    "    global frame_queue\n",
    "    \n",
    "    track_history = defaultdict(lambda: [])\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        resized_frame = cv2.resize(frame, (width // 2, height // 2))\n",
    "        height, width, _ = resized_frame.shape\n",
    "\n",
    "        tracks = yolo_obj.track(resized_frame, persist=True)\n",
    "\n",
    "        if tracks[0].boxes is not None:\n",
    "            boxes = tracks[0].boxes.xywh.cpu()\n",
    "            track_ids = tracks[0].boxes.id.int().cpu().tolist() if tracks[0].boxes.id is not None else []\n",
    "            annotated_frame = tracks[0].plot()\n",
    "\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))\n",
    "                if len(track) > 20:\n",
    "                    track.pop(0)\n",
    "\n",
    "                cv2.circle(annotated_frame, (int(x), int(y)), radius=2, color=(255, 255, 0), thickness=2)\n",
    "\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "                first_point = points[0, 0]\n",
    "                last_point = points[-1, 0]\n",
    "\n",
    "                print(f'fist point: {first_point}')\n",
    "                print(f'last point: {last_point}')\n",
    "\n",
    "                cv2.polylines(annotated_frame, [points], isClosed=False, color=(255, 0, 255), thickness=2)\n",
    "\n",
    "                get_polyline_dist(points, annotated_frame, x, y, w, h)\n",
    "\n",
    "        frame_queue.put(annotated_frame)\n",
    "\n",
    "frame_reader_thread = threading.Thread(target=read_frames, args=(yolov8_obj,))\n",
    "frame_reader_thread.daemon = True\n",
    "frame_reader_thread.start()\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        current_size = frame_queue.qsize()\n",
    "\n",
    "        if(current_size>=QUEUE_SIZE_MINIMUM_THRESHOLD):\n",
    "            frame = frame_queue.get()\n",
    "            # frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)\n",
    "\n",
    "            cv2.imshow(\"cv2\", frame)\n",
    "\n",
    "        print(\"Frame Queue Length:\", current_size)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "            time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\", e)\n",
    "finally:\n",
    "    # Release and close stream\n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import cv2\n",
    "import queue\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "from Yolo import Yolov4\n",
    "from Token import FlusonicToken\n",
    "from time import sleep\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# STREAM_URL = \"https://cctv.molecool.id/Cempaka-Putih-Timur-013/video.m3u8?token=fc7ccef3f3fa41c2644c95bbde892519795a1ec9-caaadc601326886935f88e07a2c9b193-1709180184-1709176584\"\n",
    "FPS=20\n",
    "MAX_QUEUE_SIZE = FPS*3\n",
    "FRAME_DISPLAY_INTERVAL = 1 / FPS\n",
    "QUEUE_SIZE_MINIMUM_THRESHOLD = (MAX_QUEUE_SIZE/2)\n",
    "\n",
    "MAX_QUEUE_SIZE = 100\n",
    "QUEUE_SIZE_MINIMUM_THRESHOLD = 10\n",
    "FRAME_DISPLAY_INTERVAL = 1 / 23  # Adjust as needed\n",
    "\n",
    "# Define the function to read frames\n",
    "def read_frames(yolo_obj, stream_url, frame_queue):\n",
    "    stream = cv2.VideoCapture(stream_url)\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        resized_frame = cv2.resize(frame, (width // 2, height // 2))\n",
    "        height, width, _ = resized_frame.shape\n",
    "\n",
    "        outcome = yolo_obj.Inference(image=resized_frame, original_width=width, original_height=height)\n",
    "\n",
    "        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "        _, encoded_frame = cv2.imencode('.jpg', outcome, encode_param)\n",
    "\n",
    "        frame_queue.put(encoded_frame)\n",
    "\n",
    "    stream.release()\n",
    "\n",
    "# Define the function to display frames\n",
    "def display_frames(frame_queue):\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        current_size = frame_queue.qsize()\n",
    "\n",
    "        if current_size >= QUEUE_SIZE_MINIMUM_THRESHOLD:\n",
    "            encoded_frame = frame_queue.get()\n",
    "            frame = cv2.imdecode(encoded_frame, cv2.IMREAD_COLOR)\n",
    "\n",
    "            cv2.imshow(\"cv2\", frame)\n",
    "\n",
    "        print(\"Frame Queue Length:\", current_size)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "            time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    yolov8_obj = YOLO(\"yolov8_best_visdrone.onnx\")\n",
    "    \n",
    "    token_generator = FlusonicToken('Bendungan-Hilir-005', 10).get_tokenized_url()\n",
    "    stream_url = token_generator\n",
    "\n",
    "    frame_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)\n",
    "    stream = cv2.VideoCapture(stream_url)\n",
    "\n",
    "    frame_reader_thread = threading.Thread(target=read_frames, args=(yolov8_obj,stream_url,frame_queue))\n",
    "    frame_reader_thread.daemon = True\n",
    "    frame_reader_thread.start()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            current_size = frame_queue.qsize()\n",
    "\n",
    "            if(current_size>=QUEUE_SIZE_MINIMUM_THRESHOLD):\n",
    "                frame = frame_queue.get()\n",
    "                cv2.imshow(\"cv2\", frame)\n",
    "\n",
    "            # print(\"Frame Queue Length:\", current_size)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "                break\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "                time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", e)\n",
    "    finally:\n",
    "        # Release and close stream\n",
    "        stream.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yolov8_best_visdrone.onnx for ONNX Runtime inference...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: onnx in c:\\users\\nb\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nb\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\nb\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (5.26.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.5s, installed 1 package: ['onnx']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 287.9ms\n",
      "Speed: 31.9ms preprocess, 287.9ms inference, 16.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 261.8ms\n",
      "Speed: 13.9ms preprocess, 261.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 pedestrians, 2 peoples, 1 car, 356.3ms\n",
      "Speed: 6.4ms preprocess, 356.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 377.0ms\n",
      "Speed: 16.3ms preprocess, 377.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 291.4ms\n",
      "Speed: 6.2ms preprocess, 291.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 293.8ms\n",
      "Speed: 10.8ms preprocess, 293.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 280.6ms\n",
      "Speed: 9.9ms preprocess, 280.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 430.6ms\n",
      "Speed: 32.9ms preprocess, 430.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 281.9ms\n",
      "Speed: 9.1ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 pedestrians, 1 bus, 283.1ms\n",
      "Speed: 11.8ms preprocess, 283.1ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "ERROR: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n",
      "> Overload resolution failed:\n",
      ">  - mat is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n",
      ">  - Expected Ptr<cv::UMat> for argument 'mat'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 383.3ms\n",
      "Speed: 22.2ms preprocess, 383.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 353.3ms\n",
      "Speed: 22.5ms preprocess, 353.3ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 305.0ms\n",
      "Speed: 8.7ms preprocess, 305.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 296.8ms\n",
      "Speed: 10.6ms preprocess, 296.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 353.8ms\n",
      "Speed: 18.6ms preprocess, 353.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 pedestrians, 2 cars, 489.3ms\n",
      "Speed: 14.9ms preprocess, 489.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 363.8ms\n",
      "Speed: 14.1ms preprocess, 363.8ms inference, 33.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 407.6ms\n",
      "Speed: 7.8ms preprocess, 407.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 14 pedestrians, 1 car, 331.4ms\n",
      "Speed: 5.9ms preprocess, 331.4ms inference, 11.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 22 pedestrians, 388.6ms\n",
      "Speed: 6.8ms preprocess, 388.6ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 25 pedestrians, 470.0ms\n",
      "Speed: 8.0ms preprocess, 470.0ms inference, 9.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 20 pedestrians, 1 people, 359.9ms\n",
      "Speed: 16.5ms preprocess, 359.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 17 pedestrians, 298.0ms\n",
      "Speed: 14.5ms preprocess, 298.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 pedestrians, 333.0ms\n",
      "Speed: 6.0ms preprocess, 333.0ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 1 people, 1 car, 419.0ms\n",
      "Speed: 5.5ms preprocess, 419.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 pedestrians, 3 peoples, 294.4ms\n",
      "Speed: 8.0ms preprocess, 294.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 pedestrians, 2 peoples, 293.5ms\n",
      "Speed: 9.7ms preprocess, 293.5ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 pedestrians, 289.9ms\n",
      "Speed: 9.0ms preprocess, 289.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 1 car, 1 bus, 316.0ms\n",
      "Speed: 9.1ms preprocess, 316.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 pedestrians, 3 peoples, 2 cars, 1 bus, 304.9ms\n",
      "Speed: 37.8ms preprocess, 304.9ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 2 peoples, 1 car, 372.7ms\n",
      "Speed: 13.1ms preprocess, 372.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 286.7ms\n",
      "Speed: 8.7ms preprocess, 286.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 319.2ms\n",
      "Speed: 0.0ms preprocess, 319.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 323.0ms\n",
      "Speed: 7.4ms preprocess, 323.0ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 297.0ms\n",
      "Speed: 8.0ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 289.4ms\n",
      "Speed: 7.5ms preprocess, 289.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 293.4ms\n",
      "Speed: 7.8ms preprocess, 293.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 294.1ms\n",
      "Speed: 7.0ms preprocess, 294.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 287.9ms\n",
      "Speed: 8.7ms preprocess, 287.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 375.4ms\n",
      "Speed: 9.6ms preprocess, 375.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 277.4ms\n",
      "Speed: 9.3ms preprocess, 277.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 301.2ms\n",
      "Speed: 14.9ms preprocess, 301.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 299.7ms\n",
      "Speed: 0.0ms preprocess, 299.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 4 cars, 304.4ms\n",
      "Speed: 10.7ms preprocess, 304.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 304.2ms\n",
      "Speed: 3.6ms preprocess, 304.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 pedestrians, 2 cars, 1 truck, 298.6ms\n",
      "Speed: 9.6ms preprocess, 298.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 pedestrians, 2 cars, 298.1ms\n",
      "Speed: 1.0ms preprocess, 298.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 pedestrians, 353.0ms\n",
      "Speed: 3.5ms preprocess, 353.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 pedestrians, 1 car, 299.5ms\n",
      "Speed: 7.0ms preprocess, 299.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 pedestrians, 5 cars, 1 bus, 302.8ms\n",
      "Speed: 17.2ms preprocess, 302.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 2 cars, 308.5ms\n",
      "Speed: 8.0ms preprocess, 308.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 306.3ms\n",
      "Speed: 8.5ms preprocess, 306.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 453.1ms\n",
      "Speed: 13.0ms preprocess, 453.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 401.2ms\n",
      "Speed: 15.1ms preprocess, 401.2ms inference, 13.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 380.2ms\n",
      "Speed: 5.0ms preprocess, 380.2ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 463.8ms\n",
      "Speed: 8.0ms preprocess, 463.8ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 316.0ms\n",
      "Speed: 8.3ms preprocess, 316.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 332.5ms\n",
      "Speed: 7.5ms preprocess, 332.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 315.1ms\n",
      "Speed: 5.5ms preprocess, 315.1ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 286.8ms\n",
      "Speed: 13.9ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 310.9ms\n",
      "Speed: 8.0ms preprocess, 310.9ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 364.0ms\n",
      "Speed: 8.5ms preprocess, 364.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 449.0ms\n",
      "Speed: 0.0ms preprocess, 449.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 294.7ms\n",
      "Speed: 1.1ms preprocess, 294.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 304.2ms\n",
      "Speed: 7.9ms preprocess, 304.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 333.1ms\n",
      "Speed: 10.9ms preprocess, 333.1ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 342.4ms\n",
      "Speed: 15.1ms preprocess, 342.4ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 341.9ms\n",
      "Speed: 15.8ms preprocess, 341.9ms inference, 13.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 327.7ms\n",
      "Speed: 9.5ms preprocess, 327.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 293.0ms\n",
      "Speed: 10.1ms preprocess, 293.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 307.0ms\n",
      "Speed: 12.0ms preprocess, 307.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 352.0ms\n",
      "Speed: 9.0ms preprocess, 352.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 287.3ms\n",
      "Speed: 8.1ms preprocess, 287.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 301.1ms\n",
      "Speed: 12.1ms preprocess, 301.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 293.5ms\n",
      "Speed: 11.8ms preprocess, 293.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 316.7ms\n",
      "Speed: 12.8ms preprocess, 316.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 288.8ms\n",
      "Speed: 8.8ms preprocess, 288.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 2 peoples, 338.8ms\n",
      "Speed: 8.8ms preprocess, 338.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 pedestrians, 337.9ms\n",
      "Speed: 0.0ms preprocess, 337.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 15 pedestrians, 1 car, 319.2ms\n",
      "Speed: 10.9ms preprocess, 319.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 334.1ms\n",
      "Speed: 1.1ms preprocess, 334.1ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 276.3ms\n",
      "Speed: 5.1ms preprocess, 276.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 2 cars, 3 buss, 311.8ms\n",
      "Speed: 8.0ms preprocess, 311.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 1 people, 1 car, 334.8ms\n",
      "Speed: 10.3ms preprocess, 334.8ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 14 pedestrians, 1 car, 296.8ms\n",
      "Speed: 0.0ms preprocess, 296.8ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 2 cars, 330.7ms\n",
      "Speed: 8.6ms preprocess, 330.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 290.3ms\n",
      "Speed: 8.7ms preprocess, 290.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 3 cars, 316.4ms\n",
      "Speed: 0.0ms preprocess, 316.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 4 cars, 314.5ms\n",
      "Speed: 12.5ms preprocess, 314.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 1 people, 2 cars, 357.9ms\n",
      "Speed: 14.3ms preprocess, 357.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 pedestrians, 1 people, 8 cars, 286.5ms\n",
      "Speed: 5.5ms preprocess, 286.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 287.8ms\n",
      "Speed: 0.0ms preprocess, 287.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 1 people, 3 cars, 303.3ms\n",
      "Speed: 9.0ms preprocess, 303.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 pedestrians, 1 people, 1 car, 311.5ms\n",
      "Speed: 7.4ms preprocess, 311.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 pedestrians, 1 people, 4 cars, 297.6ms\n",
      "Speed: 18.6ms preprocess, 297.6ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 pedestrians, 4 peoples, 2 cars, 303.6ms\n",
      "Speed: 8.9ms preprocess, 303.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 pedestrians, 2 peoples, 3 cars, 385.2ms\n",
      "Speed: 8.2ms preprocess, 385.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 pedestrians, 3 peoples, 2 cars, 1 van, 496.7ms\n",
      "Speed: 24.9ms preprocess, 496.7ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 pedestrians, 2 peoples, 2 cars, 337.1ms\n",
      "Speed: 6.5ms preprocess, 337.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 318.0ms\n",
      "Speed: 12.4ms preprocess, 318.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 384.0ms\n",
      "Speed: 7.3ms preprocess, 384.0ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 311.0ms\n",
      "Speed: 16.4ms preprocess, 311.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import cv2\n",
    "import queue\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "# from Yolo import Yolov4\n",
    "from Token import FlusonicToken\n",
    "from time import sleep\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# STREAM_URL = \"https://cctv.molecool.id/Cempaka-Putih-Timur-013/video.m3u8?token=fc7ccef3f3fa41c2644c95bbde892519795a1ec9-caaadc601326886935f88e07a2c9b193-1709180184-1709176584\"\n",
    "FPS=20\n",
    "MAX_QUEUE_SIZE = FPS*3\n",
    "FRAME_DISPLAY_INTERVAL = 1 / FPS\n",
    "QUEUE_SIZE_MINIMUM_THRESHOLD = (MAX_QUEUE_SIZE/2)\n",
    "\n",
    "MAX_QUEUE_SIZE = 100\n",
    "QUEUE_SIZE_MINIMUM_THRESHOLD = 10\n",
    "FRAME_DISPLAY_INTERVAL = 1 / 23  # Adjust as needed\n",
    "\n",
    "# Define the function to read frames\n",
    "def read_frames(yolo_obj, stream_url, frame_queue):\n",
    "    stream = cv2.VideoCapture(stream_url)\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        resized_frame = cv2.resize(frame, (width // 2, height // 2))\n",
    "        height, width, _ = resized_frame.shape\n",
    "\n",
    "        outcome = yolo_obj.track(resized_frame, persist=True)\n",
    "\n",
    "        # encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "        # _, encoded_frame = cv2.imencode('.jpg', outcome, encode_param)\n",
    "\n",
    "        frame_queue.put(outcome)\n",
    "\n",
    "    stream.release()\n",
    "\n",
    "# Define the function to display frames\n",
    "def display_frames(frame_queue):\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        current_size = frame_queue.qsize()\n",
    "\n",
    "        if current_size >= QUEUE_SIZE_MINIMUM_THRESHOLD:\n",
    "            # encoded_frame = frame_queue.get()\n",
    "            # frame = cv2.imdecode(encoded_frame, cv2.IMREAD_COLOR)\n",
    "\n",
    "            cv2.imshow(\"cv2\", frame_queue.get())\n",
    "\n",
    "        print(\"Frame Queue Length:\", current_size)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "            time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    yolov8_obj = YOLO(\"yolov8_best_visdrone.onnx\")\n",
    "    \n",
    "    token_generator = FlusonicToken('Bendungan-Hilir-005', 10).get_tokenized_url()\n",
    "    stream_url = token_generator\n",
    "\n",
    "    frame_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)\n",
    "    stream = cv2.VideoCapture(stream_url)\n",
    "\n",
    "    frame_reader_thread = threading.Thread(target=read_frames, args=(yolov8_obj,stream_url,frame_queue))\n",
    "    frame_reader_thread.daemon = True\n",
    "    frame_reader_thread.start()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            current_size = frame_queue.qsize()\n",
    "\n",
    "            if(current_size>=QUEUE_SIZE_MINIMUM_THRESHOLD):\n",
    "                frame = frame_queue.get()\n",
    "                cv2.imshow(\"cv2\", frame)\n",
    "\n",
    "            # print(\"Frame Queue Length:\", current_size)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "                break\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "                time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", e)\n",
    "    finally:\n",
    "        # Release and close stream\n",
    "        stream.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from Token import FlusonicToken\n",
    "import time\n",
    "\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = \"storage/cctv.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def is_valid_rtsp(url):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    if not cap.isOpened():\n",
    "        return f\"Error: Couldn't open {url}\"\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return f\"Error: Couldn't read frame from {url}\"\n",
    "    cap.release()\n",
    "    \n",
    "    return True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Access the 'cctv_flusonic' column of each row\n",
    "    if row['is_enabled'] == 1:\n",
    "        cctv_flusonic_value = row['cctv_flusonic']\n",
    "\n",
    "        token_generator = FlusonicToken(cctv_flusonic_value, 10).get_tokenized_url()\n",
    "        result = is_valid_rtsp(token_generator)\n",
    "    \n",
    "        print(f\"row {index + 1} - {cctv_flusonic_value} - {result}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADJUSTING LABEL FROM PUBLIC DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 90FA-B9DB\n",
      "\n",
      " Directory of c:\\Users\\NB\\Documents\\Object Count CCTV\n",
      "\n",
      "03/12/2024  04:27 PM    <DIR>          .\n",
      "02/27/2024  04:09 PM    <DIR>          ..\n",
      "02/29/2024  11:14 AM                35 .env\n",
      "02/29/2024  05:48 PM             2,441 backup.py\n",
      "03/12/2024  03:08 PM    <DIR>          COCO PT V8NS\n",
      "02/29/2024  11:14 AM               239 config.py\n",
      "02/28/2024  08:54 PM         3,407,916 output.mp4\n",
      "12/29/2023  03:20 PM            38,195 plot.png\n",
      "03/12/2024  10:15 AM        66,509,128 rtdetr-l.pt\n",
      "03/12/2024  04:56 PM         1,184,582 sandbox.ipynb\n",
      "03/12/2024  04:47 PM             9,753 sandbox.py\n",
      "02/29/2024  11:27 AM    <DIR>          storage\n",
      "03/07/2024  11:05 AM             2,201 test.ipynb\n",
      "02/29/2024  11:28 AM               863 Token.py\n",
      "03/12/2024  04:27 PM    <DIR>          training dfs\n",
      "02/28/2024  08:16 PM             5,570 Yolo.py\n",
      "02/28/2024  01:27 PM    <DIR>          YOLOv4\n",
      "03/12/2024  01:24 PM        52,117,635 yolov8m.pt\n",
      "02/29/2024  02:23 PM         6,534,387 yolov8n.pt\n",
      "03/12/2024  10:11 AM        22,573,363 yolov8s.pt\n",
      "03/12/2024  10:12 AM       136,867,539 yolov8x.pt\n",
      "03/12/2024  11:21 AM        51,802,599 yolov9c.pt\n",
      "03/12/2024  11:45 AM       117,530,476 yolov9e.pt\n",
      "02/29/2024  11:28 AM    <DIR>          __pycache__\n",
      "              17 File(s)    458,586,922 bytes\n",
      "               7 Dir(s)  137,044,598,784 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the mapping for label simplification\n",
    "label_mapping = {\n",
    "    0: 5,  # bus\n",
    "    1: 5,  # bus\n",
    "    2: 2,  # car\n",
    "    3: 7,  # truck\n",
    "    4: 5,  # bus\n",
    "    5: 7,  # truck\n",
    "    6: 5,  # bus\n",
    "    7: 7,  # truck\n",
    "    8: 7,  # truck\n",
    "    9: 7,  # truck\n",
    "    10: 7, # truck\n",
    "    11: 7  # truck\n",
    "}\n",
    "\n",
    "# Path to the folder containing the text files\n",
    "folder_path = 'training dfs/Venom.v8i.yolov8/valid/labels'\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the contents of the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Process each line in the file\n",
    "        processed_lines = []\n",
    "        for line in lines:\n",
    "            # Split the line into label and xywh\n",
    "            parts = line.strip().split(' ')\n",
    "            label = int(parts[0])\n",
    "            \n",
    "            # Replace the label number according to the mapping\n",
    "            simplified_label = label_mapping.get(label, label)\n",
    "            parts[0] = str(simplified_label)\n",
    "            \n",
    "            # Join the parts back together and append to the processed lines\n",
    "            processed_lines.append(' '.join(parts))\n",
    "        \n",
    "        # Write the processed lines back to the file\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write('\\n'.join(processed_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8_best_visdrone.pt')\n",
    "\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ovino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\reshape_layer.cpp:109: error: (-215:Assertion failed) total(srcShape, srcRange.start, srcRange.end) == maskTotal in function 'cv::dnn::computeShapeByReshapeMask'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m672\u001b[39m, \u001b[38;5;241m384\u001b[39m))\n\u001b[0;32m     17\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 18\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m     21\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(detection[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\reshape_layer.cpp:109: error: (-215:Assertion failed) total(srcShape, srcRange.start, srcRange.end) == maskTotal in function 'cv::dnn::computeShapeByReshapeMask'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# net = cv.dnn.readNet('/yolov8_best_visdrone_openvino_model/yolov8_best_visdrone.bin',\n",
    "#                      '/yolov8_best_visdrone_openvino_model/yolov8_best_visdrone.xml')\n",
    "\n",
    "net = cv.dnn.readNetFromONNX('yolov8_best_visdrone.onnx')\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while cv.waitKey(1) < 0:\n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        break\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frame, size=(672, 384))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()\n",
    "\n",
    "    for detection in out.reshape(-1, 7):\n",
    "        confidence = float(detection[2])\n",
    "        xmin = int(detection[3] * frame.shape[1])\n",
    "        ymin = int(detection[4] * frame.shape[0])\n",
    "        xmax = int(detection[5] * frame.shape[1])\n",
    "        ymax = int(detection[6] * frame.shape[0])\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            cv.rectangle(frame, (xmin, ymin), (xmax, ymax), color=(0, 255, 0))\n",
    "\n",
    "    cv.imshow('OpenVINO face detection', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m         processing_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m processing_time \u001b[38;5;241m<\u001b[39m FRAME_DISPLAY_INTERVAL:\n\u001b[1;32m---> 75\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFRAME_DISPLAY_INTERVAL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprocessing_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Token import FlusonicToken\n",
    "import cv2\n",
    "import numpy as np\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def read_frames(car_cascade):\n",
    "    global frame_queue\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        screen_width = 1280\n",
    "        screen_height = 720\n",
    "        scaling_factor = min(screen_width / width, screen_height / height)\n",
    "        resized_width = int(width * scaling_factor)\n",
    "        resized_height = int(height * scaling_factor)\n",
    "        resized_frame = cv2.resize(frame, (resized_width, resized_height))\n",
    "        \n",
    "        grey = cv2.cvtColor(resized_frame,cv2.COLOR_BGR2GRAY)\n",
    "        # blur = cv2.GaussianBlur(grey,(5,5),0)\n",
    "        # dilated = cv2.dilate(blur,np.ones((3,3)))\n",
    "        # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "        # closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel) \n",
    "\n",
    "        \n",
    "        cars = car_cascade.detectMultiScale(grey, 1.1, 1)\n",
    "\n",
    "        # cnt = 0\n",
    "        for (x,y,w,h) in cars:\n",
    "            cv2.rectangle(resized_frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            # cnt += 1\n",
    "        # print(cnt, \" cars found\")\n",
    "        frame_queue.put(resized_frame)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FPS=30\n",
    "    MAX_QUEUE_SIZE = FPS*3\n",
    "    FRAME_DISPLAY_INTERVAL = 1 / FPS\n",
    "    QUEUE_SIZE_MINIMUM_THRESHOLD = (FPS)\n",
    "    token_generator = FlusonicToken('GBK-003', 10).get_tokenized_url()\n",
    "    stream_url = token_generator\n",
    "\n",
    "    frame_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)\n",
    "    stream = cv2.VideoCapture(stream_url)\n",
    "\n",
    "    cascade_src = 'cars2.xml'\n",
    "    car_cascade = cv2.CascadeClassifier(cascade_src)\n",
    "\n",
    "    frame_reader_thread = threading.Thread(target=read_frames, args=(car_cascade,))\n",
    "    frame_reader_thread.daemon = True\n",
    "    frame_reader_thread.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        current_size = frame_queue.qsize()\n",
    "\n",
    "        if(current_size>=QUEUE_SIZE_MINIMUM_THRESHOLD):\n",
    "            frame = frame_queue.get()\n",
    "            cv2.imshow(\"cv2\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        if processing_time < FRAME_DISPLAY_INTERVAL:\n",
    "            time.sleep(FRAME_DISPLAY_INTERVAL - processing_time)\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\", e)\n",
    "finally:\n",
    "    # Release and close stream\n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: efficientDet-D1/saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the EfficientDet model from the protobuf file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromTensorflow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mefficientDet-D1/saved_model.pb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the input image\u001b[39;00m\n\u001b[0;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC://Users//NB//Pictures//maxresdefault.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: efficientDet-D1/saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the EfficientDet model from the protobuf file\n",
    "model = cv2.dnn.readNetFromTensorflow('efficientDet-D1/saved_model.pb')\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('C://Users//NB//Pictures//maxresdefault.jpg')\n",
    "\n",
    "# Resize the input image to the expected input size of the model\n",
    "input_size = (640, 640)  # Adjust this size according to the model's input requirements\n",
    "resized_image = cv2.resize(image, input_size)\n",
    "\n",
    "# Preprocess input data (normalize pixel values, scale to range [-1, 1], etc.)\n",
    "preprocessed_image = resized_image.astype(np.float32) / 255.0  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "# Convert the image to the format expected by the model\n",
    "input_blob = cv2.dnn.blobFromImage(preprocessed_image)\n",
    "\n",
    "# Set the input blob for the model\n",
    "model.setInput(input_blob)\n",
    "\n",
    "# Forward pass through the network to perform inference\n",
    "output = model.forward()\n",
    "\n",
    "# Postprocess the model predictions\n",
    "# EfficientDet typically outputs bounding boxes, class labels, and confidence scores\n",
    "# You may need to parse the output tensor and apply non-maximum suppression (NMS) to filter out overlapping boxes\n",
    "# For simplicity, let's assume the output contains bounding boxes in the format [x_min, y_min, x_max, y_max]\n",
    "# where (x_min, y_min) and (x_max, y_max) are the top-left and bottom-right coordinates of the bounding box\n",
    "\n",
    "# Iterate over the detected objects and draw bounding boxes on the original image\n",
    "for detection in output[0, 0]:  # Iterate over detected objects\n",
    "    confidence = detection[2]  # Confidence score\n",
    "    if confidence > 0.5:  # Filter out low-confidence detections\n",
    "        x_min = int(detection[3] * image.shape[1])\n",
    "        y_min = int(detection[4] * image.shape[0])\n",
    "        x_max = int(detection[5] * image.shape[1])\n",
    "        y_max = int(detection[6] * image.shape[0])\n",
    "        class_id = int(detection[1])  # Class label\n",
    "\n",
    "        # Draw bounding box rectangle on the original image\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "        # Display class label and confidence score near the bounding box\n",
    "        label = f'Class: {class_id}, Confidence: {confidence:.2f}'\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the resulting image with detections\n",
    "cv2.imshow('Detection Results', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'openvino' has no attribute 'Core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mov\u001b[39;00m\n\u001b[0;32m      2\u001b[0m core \u001b[38;5;241m=\u001b[39m ov\u001b[38;5;241m.\u001b[39mCore()\n",
      "File \u001b[1;32mc:\\Users\\NB\\Documents\\Object Count CCTV\\openvino.py:34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import cv2 as cv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(cv.dnn.getAvailableBackends())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     cv.imshow('OpenVINO face detection', frame)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mov\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m core \u001b[38;5;241m=\u001b[39m \u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCore\u001b[49m()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(core\u001b[38;5;241m.\u001b[39mavailable_devices)\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'openvino' has no attribute 'Core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "core = ov.Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'openvino' has no attribute 'Core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mov\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NB\\Documents\\Object Count CCTV\\openvino.py:34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import cv2 as cv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(cv.dnn.getAvailableBackends())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     cv.imshow('OpenVINO face detection', frame)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mov\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m core \u001b[38;5;241m=\u001b[39m \u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCore\u001b[49m()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(core\u001b[38;5;241m.\u001b[39mavailable_devices)\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'openvino' has no attribute 'Core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import openvino as ov \n",
    "import tensorflow as tf\n",
    "\n",
    "# 1a. Convert model created with TF code\n",
    "model = tf.keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
    "ov_model = ov.convert_model(model)\n",
    "\n",
    "# 1b. Convert model from file\n",
    "ov_model = ov.convert_model(\"model.pb\")\n",
    "\n",
    "\n",
    "# 2. Compile model from memory\n",
    "core = ov.Core()\n",
    "compiled_model = core.compile_model(ov_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
